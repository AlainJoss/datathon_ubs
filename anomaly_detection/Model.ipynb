{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0be101c",
   "metadata": {},
   "source": [
    "<h1 style=\"color:DarkRed;\">UBS Challenge 4ML: Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6d33396",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.011551700Z",
     "start_time": "2024-04-28T09:05:10.920580400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14ba2ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:10.929617100Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65970b6",
   "metadata": {},
   "source": [
    "We will start with a simple machine learning method and then advancing to more complex deep learning models makes sense for anomaly detection in an unsupervised setting. We'll begin with the Isolation Forest algorithm (does not require the data to have any specific distribution neither further assumprions).\n",
    "\n",
    "- For the feature Selection: We'll use rate of change features such as \"likes_per_content_weekly_change\", \"followers_weekly_change\", and \"comments_per_likes_weekly_change\" as these reflect relative changes over time and are comparable across different entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d35f2f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.090895900Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"likes_per_content_weekly_change\", \n",
    "    \"followers_weekly_change\", \n",
    "    \"comments_per_likes_weekly_change\",\n",
    "    \"comments_per_likes_ma_2\",\n",
    "    \"comments_per_likes_ma_3\",\n",
    "    \"change_followers_ma_3\",\n",
    "    \"comments_per_likes_ma_5\",\n",
    "    \"change_followers_ma_5\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c739100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.094793300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\ipykernel_18832\\2035501673.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['comments_per_likes_weekly_change'].replace([float('inf'), float('-inf')], 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# We can assume no change\n",
    "df['comments_per_likes_weekly_change'].replace([float('inf'), float('-inf')], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc3b367",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04572c10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.126493600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let´s start with an Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2185893f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.131986600Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 16),  \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, input_size),\n",
    "            nn.Sigmoid(),  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb6a02f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.150312900Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'likes_per_content_weekly_change',\n",
    "    'followers_weekly_change',\n",
    "    'comments_per_likes_weekly_change',\n",
    "    'comments_per_likes_ma_2',\n",
    "    'comments_per_likes_ma_3',\n",
    "    'change_followers_ma_3',\n",
    "    'comments_per_likes_ma_5',\n",
    "    'change_followers_ma_5'\n",
    "]\n",
    "\n",
    "data_tensor = torch.tensor(df[features].values.astype(np.float32))\n",
    "\n",
    "dataset = TensorDataset(data_tensor, data_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe10280b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:11.202763500Z",
     "start_time": "2024-04-28T09:05:11.156918100Z"
    }
   },
   "outputs": [],
   "source": [
    "model = SimpleAutoencoder(input_size=len(features))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "num_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcd8019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:52.827964400Z",
     "start_time": "2024-04-28T09:05:11.171110700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 71.5278\n",
      "Epoch [2/30], Loss: 565.9390\n",
      "Epoch [3/30], Loss: 50.8334\n",
      "Epoch [4/30], Loss: 79.0865\n",
      "Epoch [5/30], Loss: 251.3141\n",
      "Epoch [6/30], Loss: 159.7114\n",
      "Epoch [7/30], Loss: 384.7322\n",
      "Epoch [8/30], Loss: 118.9860\n",
      "Epoch [9/30], Loss: 274.0675\n",
      "Epoch [10/30], Loss: 529.8152\n",
      "Epoch [11/30], Loss: 515.5925\n",
      "Epoch [12/30], Loss: 112.5311\n",
      "Epoch [13/30], Loss: 76.5704\n",
      "Epoch [14/30], Loss: 186.2516\n",
      "Epoch [15/30], Loss: 70.9919\n",
      "Epoch [16/30], Loss: 106.1724\n",
      "Epoch [17/30], Loss: 115.6929\n",
      "Epoch [18/30], Loss: 385.9139\n",
      "Epoch [19/30], Loss: 110.6106\n",
      "Epoch [20/30], Loss: 104.4592\n",
      "Epoch [21/30], Loss: 28.8483\n",
      "Epoch [22/30], Loss: 159.4747\n",
      "Epoch [23/30], Loss: 156.2186\n",
      "Epoch [24/30], Loss: 118.5340\n",
      "Epoch [25/30], Loss: 3636.8516\n",
      "Epoch [26/30], Loss: 473.3210\n",
      "Epoch [27/30], Loss: 50.2081\n",
      "Epoch [28/30], Loss: 976.7182\n",
      "Epoch [29/30], Loss: 96.9131\n",
      "Epoch [30/30], Loss: 2187.0176\n",
      "Anomalies detected: 1515\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    for inputs, _ in dataloader:\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "model.eval() \n",
    "reconstruction_errors = []\n",
    "\n",
    "for inputs, _ in dataloader:\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        sample_losses = ((inputs - outputs) ** 2).mean(dim=1)\n",
    "        reconstruction_errors.extend(sample_losses.cpu().numpy())\n",
    "\n",
    "\n",
    "reconstruction_errors = np.array(reconstruction_errors)\n",
    "\n",
    "\n",
    "error_threshold = np.percentile(reconstruction_errors, 95)\n",
    "\n",
    "anomalies_indices = np.where(reconstruction_errors > error_threshold)[0]\n",
    "\n",
    "anomalies_autoencoder = df.iloc[anomalies_indices]\n",
    "\n",
    "print(f'Anomalies detected: {len(anomalies_indices)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee7c8d2",
   "metadata": {},
   "source": [
    "The results does not look good in terms of converence. Probably the dataset is not the most suitable for this type of anomaly detection. However, let´s look which variables influenciate the most:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41a9e46a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:55.911814500Z",
     "start_time": "2024-04-28T09:05:52.835245300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\ipykernel_18832\\4076661949.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomalies_autoencoder[\"Relevant Features\"] = anomalies_data\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "detailed_errors = []\n",
    "\n",
    "for inputs, _ in dataloader:\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        batch_errors = (inputs - outputs) ** 2\n",
    "        detailed_errors.append(batch_errors)\n",
    "\n",
    "\n",
    "detailed_errors = torch.cat(detailed_errors, dim=0)\n",
    "\n",
    "anomalies_data = []\n",
    "\n",
    "for index in anomalies_indices:\n",
    "    instance = df[features].iloc[index]\n",
    "    error = detailed_errors[index] \n",
    "    \n",
    "    high_error_features_indices = np.where(error > 0.95)[0] \n",
    "    high_error_features = df[features].columns[high_error_features_indices].tolist()\n",
    "    \n",
    "    anomalies_data.append(', '.join(high_error_features)\n",
    "    )\n",
    "\n",
    "\n",
    "anomalies_autoencoder[\"Relevant Features\"] = anomalies_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0545b18b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:55.925475500Z",
     "start_time": "2024-04-28T09:05:55.911814500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1        likes_per_content_weekly_change, comments_per_...\n2        likes_per_content_weekly_change, comments_per_...\n48       likes_per_content_weekly_change, comments_per_...\n57       likes_per_content_weekly_change, comments_per_...\n89       likes_per_content_weekly_change, comments_per_...\n                               ...                        \n30193    likes_per_content_weekly_change, comments_per_...\n30196    likes_per_content_weekly_change, comments_per_...\n30201    likes_per_content_weekly_change, comments_per_...\n30211                     comments_per_likes_weekly_change\n30233    likes_per_content_weekly_change, comments_per_...\nName: Relevant Features, Length: 1515, dtype: object"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_autoencoder[\"Relevant Features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9680f5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:55.973487400Z",
     "start_time": "2024-04-28T09:05:55.925475500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "likes_per_content_weekly_change: 1381\n",
      "comments_per_likes_weekly_change: 1400\n",
      "followers_weekly_change: 65\n",
      "change_followers_ma_3: 68\n",
      "change_followers_ma_5: 61\n",
      ": 17\n",
      "comments_per_likes_ma_2: 3\n",
      "comments_per_likes_ma_3: 3\n",
      "comments_per_likes_ma_5: 1\n"
     ]
    }
   ],
   "source": [
    "# Let´s analyse the results:\n",
    "\n",
    "all_features = ', '.join(anomalies_autoencoder['Relevant Features'])\n",
    "\n",
    "feature_list = all_features.split(', ')\n",
    "\n",
    "feature_counts = Counter(feature_list)\n",
    "\n",
    "for feature, count in feature_counts.items():\n",
    "    print(f\"{feature}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a6a0b",
   "metadata": {},
   "source": [
    "#### We can see that comments_per_likes_weekly_change and likes_per_content_weekly_change where the ones that possible \"generated\" the anomalies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78339f4e",
   "metadata": {},
   "source": [
    "After some empirical validation of the results, we can see (again) that autoencoder is not the best choice. Let´s try something simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a73fd643",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:55.987344200Z",
     "start_time": "2024-04-28T09:05:55.947136300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92bd7132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.321404200Z",
     "start_time": "2024-04-28T09:05:55.983220700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "IsolationForest(contamination=0.01, random_state=42)",
      "text/html": "<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;IsolationForest<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.IsolationForest.html\">?<span>Documentation for IsolationForest</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>IsolationForest(contamination=0.01, random_state=42)</pre></div> </div></div></div></div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iso_forest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "iso_forest.fit(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1a5c43c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.863833700Z",
     "start_time": "2024-04-28T09:05:56.316920600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['anomaly_iso_forest'] = iso_forest.predict(df_scaled)\n",
    "df['anomaly_score'] = iso_forest.decision_function(df_scaled)\n",
    "\n",
    "plt.hist(df['anomaly_score'], bins=50)\n",
    "plt.xlabel('Anomaly Score')\n",
    "plt.ylabel('Number of Observations')\n",
    "plt.title('Distribution of Anomaly Scores')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d853ccd",
   "metadata": {},
   "source": [
    "The x-axis indicates the range of anomaly scores. Scores close to 0 indicate less anomalous data points, while those moving away from 0 (towards -0.2 and 0.3) indicate more anomalous data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32b7a623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.879270400Z",
     "start_time": "2024-04-28T09:05:56.863833700Z"
    }
   },
   "outputs": [],
   "source": [
    "anomalies_iso_forest = df[df['anomaly_iso_forest'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f021a85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.960787Z",
     "start_time": "2024-04-28T09:05:56.881665900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0 legal_entity        date  followers  pictures  videos  \\\n12             12       AbbVie  2021-11-20     9187.0       4.0     0.0   \n1949         1949   Beiersdorf  2016-07-23     9168.0       9.0     1.0   \n1950         1950   Beiersdorf  2016-07-30     9917.0      10.0     2.0   \n1951         1951   Beiersdorf  2016-08-06    10677.0       9.0     1.0   \n1952         1952   Beiersdorf  2016-08-13    11167.0       6.0     2.0   \n...           ...          ...         ...        ...       ...     ...   \n30284       30284  iRobot Corp  2023-08-12   307626.0      90.0    58.0   \n30285       30285  iRobot Corp  2023-08-19   307679.0      90.0    59.0   \n30286       30286  iRobot Corp  2023-08-26   307842.0      96.0    74.0   \n30287       30287  iRobot Corp  2023-09-02   307980.0      94.0    71.0   \n30288       30288  iRobot Corp  2023-09-09   308043.0      89.0    90.0   \n\n       comments   likes       close  content  ...  change_followers_ma_2  \\\n12          0.0   228.0  107.903076      4.0  ...               5.553877   \n1949       76.0  4030.0   77.994331     10.0  ...               6.069415   \n1950      109.0  5116.0   79.965179     12.0  ...               7.374793   \n1951       93.0  4441.0   79.220207     10.0  ...               7.916664   \n1952       84.0  3883.0   79.342796      8.0  ...               6.126456   \n...         ...     ...         ...      ...  ...                    ...   \n30284    3994.0  2264.0   39.110001    148.0  ...               0.009430   \n30285    2989.0  2124.0   38.770000    149.0  ...               0.023409   \n30286    3092.0  2903.0   36.340000    170.0  ...               0.035103   \n30287    3038.0  2574.0   35.099998    165.0  ...               0.048903   \n30288    3044.0  2805.0   37.299999    179.0  ...               0.032642   \n\n       Close_price_weekly_change_ma_2  comments_per_likes_ma_3  \\\n12                           1.120340                 0.000000   \n1949                        -0.910379                 0.022538   \n1950                         0.501464                 0.020999   \n1951                         0.797646                 0.020368   \n1952                        -0.388438                 0.021293   \n...                               ...                      ...   \n30284                        1.887084                 1.842369   \n30285                        2.459566                 1.662296   \n30286                       -3.568538                 1.412163   \n30287                       -4.839978                 1.217540   \n30288                        1.427793                 1.110191   \n\n       change_followers_ma_3  Close_price_weekly_change_ma_3  \\\n12                  4.577813                        0.538866   \n1949                5.825835                       -0.535544   \n1950                6.769517                        0.235385   \n1951                7.471065                        0.023769   \n1952                6.807544                        0.583345   \n...                      ...                             ...   \n30284               0.011381                        0.131296   \n30285               0.012030                        0.968275   \n30286               0.033265                       -0.449534   \n30287               0.038345                       -3.516433   \n30288               0.039420                       -1.137382   \n\n       comments_per_likes_ma_5  change_followers_ma_5  \\\n12                    0.000000               3.864647   \n1949                  0.025072               6.140940   \n1950                  0.023310               6.478969   \n1951                  0.021972               6.662167   \n1952                  0.021114               6.512292   \n...                        ...                    ...   \n30284                 1.782597               0.016654   \n30285                 1.781647               0.018928   \n30286                 1.599893               0.020870   \n30287                 1.446451               0.026779   \n30288                 1.300392               0.033016   \n\n       Close_price_weekly_change_ma_5  anomaly_iso_forest  anomaly_score  \n12                           0.725255                  -1      -0.002253  \n1949                        -0.439669                  -1      -0.010010  \n1950                         0.082272                  -1      -0.016080  \n1951                        -0.002268                  -1      -0.011292  \n1952                        -0.014144                  -1      -0.005920  \n...                               ...                 ...            ...  \n30284                       -3.493341                  -1      -0.057105  \n30285                       -0.347936                  -1      -0.070575  \n30286                       -1.348638                  -1      -0.064426  \n30287                       -1.355026                  -1      -0.059263  \n30288                        0.301397                  -1      -0.046276  \n\n[303 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>legal_entity</th>\n      <th>date</th>\n      <th>followers</th>\n      <th>pictures</th>\n      <th>videos</th>\n      <th>comments</th>\n      <th>likes</th>\n      <th>close</th>\n      <th>content</th>\n      <th>...</th>\n      <th>change_followers_ma_2</th>\n      <th>Close_price_weekly_change_ma_2</th>\n      <th>comments_per_likes_ma_3</th>\n      <th>change_followers_ma_3</th>\n      <th>Close_price_weekly_change_ma_3</th>\n      <th>comments_per_likes_ma_5</th>\n      <th>change_followers_ma_5</th>\n      <th>Close_price_weekly_change_ma_5</th>\n      <th>anomaly_iso_forest</th>\n      <th>anomaly_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>AbbVie</td>\n      <td>2021-11-20</td>\n      <td>9187.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>107.903076</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>5.553877</td>\n      <td>1.120340</td>\n      <td>0.000000</td>\n      <td>4.577813</td>\n      <td>0.538866</td>\n      <td>0.000000</td>\n      <td>3.864647</td>\n      <td>0.725255</td>\n      <td>-1</td>\n      <td>-0.002253</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>1949</td>\n      <td>Beiersdorf</td>\n      <td>2016-07-23</td>\n      <td>9168.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>76.0</td>\n      <td>4030.0</td>\n      <td>77.994331</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>6.069415</td>\n      <td>-0.910379</td>\n      <td>0.022538</td>\n      <td>5.825835</td>\n      <td>-0.535544</td>\n      <td>0.025072</td>\n      <td>6.140940</td>\n      <td>-0.439669</td>\n      <td>-1</td>\n      <td>-0.010010</td>\n    </tr>\n    <tr>\n      <th>1950</th>\n      <td>1950</td>\n      <td>Beiersdorf</td>\n      <td>2016-07-30</td>\n      <td>9917.0</td>\n      <td>10.0</td>\n      <td>2.0</td>\n      <td>109.0</td>\n      <td>5116.0</td>\n      <td>79.965179</td>\n      <td>12.0</td>\n      <td>...</td>\n      <td>7.374793</td>\n      <td>0.501464</td>\n      <td>0.020999</td>\n      <td>6.769517</td>\n      <td>0.235385</td>\n      <td>0.023310</td>\n      <td>6.478969</td>\n      <td>0.082272</td>\n      <td>-1</td>\n      <td>-0.016080</td>\n    </tr>\n    <tr>\n      <th>1951</th>\n      <td>1951</td>\n      <td>Beiersdorf</td>\n      <td>2016-08-06</td>\n      <td>10677.0</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>93.0</td>\n      <td>4441.0</td>\n      <td>79.220207</td>\n      <td>10.0</td>\n      <td>...</td>\n      <td>7.916664</td>\n      <td>0.797646</td>\n      <td>0.020368</td>\n      <td>7.471065</td>\n      <td>0.023769</td>\n      <td>0.021972</td>\n      <td>6.662167</td>\n      <td>-0.002268</td>\n      <td>-1</td>\n      <td>-0.011292</td>\n    </tr>\n    <tr>\n      <th>1952</th>\n      <td>1952</td>\n      <td>Beiersdorf</td>\n      <td>2016-08-13</td>\n      <td>11167.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>84.0</td>\n      <td>3883.0</td>\n      <td>79.342796</td>\n      <td>8.0</td>\n      <td>...</td>\n      <td>6.126456</td>\n      <td>-0.388438</td>\n      <td>0.021293</td>\n      <td>6.807544</td>\n      <td>0.583345</td>\n      <td>0.021114</td>\n      <td>6.512292</td>\n      <td>-0.014144</td>\n      <td>-1</td>\n      <td>-0.005920</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>30284</th>\n      <td>30284</td>\n      <td>iRobot Corp</td>\n      <td>2023-08-12</td>\n      <td>307626.0</td>\n      <td>90.0</td>\n      <td>58.0</td>\n      <td>3994.0</td>\n      <td>2264.0</td>\n      <td>39.110001</td>\n      <td>148.0</td>\n      <td>...</td>\n      <td>0.009430</td>\n      <td>1.887084</td>\n      <td>1.842369</td>\n      <td>0.011381</td>\n      <td>0.131296</td>\n      <td>1.782597</td>\n      <td>0.016654</td>\n      <td>-3.493341</td>\n      <td>-1</td>\n      <td>-0.057105</td>\n    </tr>\n    <tr>\n      <th>30285</th>\n      <td>30285</td>\n      <td>iRobot Corp</td>\n      <td>2023-08-19</td>\n      <td>307679.0</td>\n      <td>90.0</td>\n      <td>59.0</td>\n      <td>2989.0</td>\n      <td>2124.0</td>\n      <td>38.770000</td>\n      <td>149.0</td>\n      <td>...</td>\n      <td>0.023409</td>\n      <td>2.459566</td>\n      <td>1.662296</td>\n      <td>0.012030</td>\n      <td>0.968275</td>\n      <td>1.781647</td>\n      <td>0.018928</td>\n      <td>-0.347936</td>\n      <td>-1</td>\n      <td>-0.070575</td>\n    </tr>\n    <tr>\n      <th>30286</th>\n      <td>30286</td>\n      <td>iRobot Corp</td>\n      <td>2023-08-26</td>\n      <td>307842.0</td>\n      <td>96.0</td>\n      <td>74.0</td>\n      <td>3092.0</td>\n      <td>2903.0</td>\n      <td>36.340000</td>\n      <td>170.0</td>\n      <td>...</td>\n      <td>0.035103</td>\n      <td>-3.568538</td>\n      <td>1.412163</td>\n      <td>0.033265</td>\n      <td>-0.449534</td>\n      <td>1.599893</td>\n      <td>0.020870</td>\n      <td>-1.348638</td>\n      <td>-1</td>\n      <td>-0.064426</td>\n    </tr>\n    <tr>\n      <th>30287</th>\n      <td>30287</td>\n      <td>iRobot Corp</td>\n      <td>2023-09-02</td>\n      <td>307980.0</td>\n      <td>94.0</td>\n      <td>71.0</td>\n      <td>3038.0</td>\n      <td>2574.0</td>\n      <td>35.099998</td>\n      <td>165.0</td>\n      <td>...</td>\n      <td>0.048903</td>\n      <td>-4.839978</td>\n      <td>1.217540</td>\n      <td>0.038345</td>\n      <td>-3.516433</td>\n      <td>1.446451</td>\n      <td>0.026779</td>\n      <td>-1.355026</td>\n      <td>-1</td>\n      <td>-0.059263</td>\n    </tr>\n    <tr>\n      <th>30288</th>\n      <td>30288</td>\n      <td>iRobot Corp</td>\n      <td>2023-09-09</td>\n      <td>308043.0</td>\n      <td>89.0</td>\n      <td>90.0</td>\n      <td>3044.0</td>\n      <td>2805.0</td>\n      <td>37.299999</td>\n      <td>179.0</td>\n      <td>...</td>\n      <td>0.032642</td>\n      <td>1.427793</td>\n      <td>1.110191</td>\n      <td>0.039420</td>\n      <td>-1.137382</td>\n      <td>1.300392</td>\n      <td>0.033016</td>\n      <td>0.301397</td>\n      <td>-1</td>\n      <td>-0.046276</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_iso_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79888360",
   "metadata": {},
   "source": [
    "Let´s see if, according to this model, the anomalies have some implications on the financial results of the underlying stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af4c6a",
   "metadata": {},
   "source": [
    "For us, is important to understand why the model decides when an observation is an anomally or not. Let´s do some statistical analysis (assuming the data is normally distributed), computing confidence intervals and assuming that, when a column is outside the confidence interval, could be one of the reasons why the model decided the observation was classified as an anomaly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55fca402",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.960787Z",
     "start_time": "2024-04-28T09:05:56.917932200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly at index 12:\n",
      "Feature followers_weekly_change with value 6.90016290435187 is outside the typical range of (-1.8395283385556915, 2.706959280882657).\n",
      "Feature change_followers_ma_3 with value 4.577812654493877 is outside the typical range of (-1.3006478511772894, 2.178664210512727).\n",
      "Feature change_followers_ma_5 with value 3.864647184445529 is outside the typical range of (-1.205327433146739, 2.0934304515462863).\n",
      "\n",
      "\n",
      "Anomaly at index 1949:\n",
      "Feature followers_weekly_change with value 6.579865147640085 is outside the typical range of (-1.8395283385556915, 2.706959280882657).\n",
      "Feature change_followers_ma_3 with value 5.82583525208263 is outside the typical range of (-1.3006478511772894, 2.178664210512727).\n",
      "Feature change_followers_ma_5 with value 6.140940460982898 is outside the typical range of (-1.205327433146739, 2.0934304515462863).\n",
      "\n",
      "\n",
      "Anomaly at index 1950:\n",
      "Feature followers_weekly_change with value 8.169720767888311 is outside the typical range of (-1.8395283385556915, 2.706959280882657).\n",
      "Feature change_followers_ma_3 with value 6.769516735208447 is outside the typical range of (-1.3006478511772894, 2.178664210512727).\n",
      "Feature change_followers_ma_5 with value 6.478969245768317 is outside the typical range of (-1.205327433146739, 2.0934304515462863).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, anomaly in anomalies_iso_forest.iloc[:3,:].iterrows():\n",
    "    print(f\"Anomaly at index {index}:\")\n",
    "    for feature in features:\n",
    "        value = anomaly[feature]\n",
    "        typical_range = (df[feature].mean() - 2 * df[feature].std(), df[feature].mean() + 2 * df[feature].std())\n",
    "        if not (typical_range[0] <= value <= typical_range[1]):\n",
    "            print(f\"Feature {feature} with value {value} is outside the typical range of {typical_range}.\")\n",
    "            \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c2156d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:56.961810800Z",
     "start_time": "2024-04-28T09:05:56.940410700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now, let´s define a function to store this results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ec75139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.669896200Z",
     "start_time": "2024-04-28T09:05:56.947196900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\ipykernel_18832\\31888562.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomalies_iso_forest['outlier_features'] = anomalies_iso_forest.apply(find_outliers, axis=1, features=features, df=df)\n"
     ]
    }
   ],
   "source": [
    "def find_outliers(row, features, df):\n",
    "    outlier_features = []\n",
    "    for feature in features:\n",
    "        value = row[feature]\n",
    "        typical_range = (df[feature].mean() - 2 * df[feature].std(), df[feature].mean() + 2 * df[feature].std())\n",
    "        if not (typical_range[0] <= value <= typical_range[1]):\n",
    "            outlier_features.append(feature)\n",
    "    return ', '.join(outlier_features)\n",
    "\n",
    "anomalies_iso_forest['outlier_features'] = anomalies_iso_forest.apply(find_outliers, axis=1, features=features, df=df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da953aac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.682463800Z",
     "start_time": "2024-04-28T09:05:58.669896200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'followers_weekly_change, change_followers_ma_3, change_followers_ma_5'"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let´s look to an example\n",
    "anomalies_iso_forest.loc[12,'outlier_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04819cfb",
   "metadata": {},
   "source": [
    "Let´s make an analysis of how those variables impact on the decisions and let´s use the findings into a investing strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d57f709a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.738798Z",
     "start_time": "2024-04-28T09:05:58.683692400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "followers_weekly_change: 86\n",
      "change_followers_ma_3: 96\n",
      "change_followers_ma_5: 94\n",
      "comments_per_likes_ma_2: 220\n",
      "comments_per_likes_ma_3: 218\n",
      "comments_per_likes_ma_5: 210\n",
      "comments_per_likes_weekly_change: 41\n",
      "likes_per_content_weekly_change: 9\n",
      ": 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_features = ', '.join(anomalies_iso_forest['outlier_features'])\n",
    "\n",
    "feature_list = all_features.split(', ')\n",
    "\n",
    "feature_counts = Counter(feature_list)\n",
    "\n",
    "for feature, count in feature_counts.items():\n",
    "    print(f\"{feature}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7de5b",
   "metadata": {},
   "source": [
    "It is interesting to see that the MA comments per likes are the most important ones. Also, followers_weekly_change keeps its importance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c57b410",
   "metadata": {},
   "source": [
    "Now, let´s transform this insights into value. What would we expect?\n",
    "\n",
    "- If followers decreases significantly: probably a \"scandal\" happened on the company, thus the stock price will go down. \n",
    "- If comments_per_likes_weekly_change goes up: We assume that could be due to \"negative\" comments. We would expect the stock going down. An increase, may suggest a possitive engagment, but probably it will not be reflected on our financial data application.\n",
    "- If likes_per_content_weekly_change goes up: Increased engagement may indicate positive reception or interest in the company's activities, possibly a bullish signal for the stock. The opposite interpretation is analogous.\n",
    "- If followers increases significantly: goes up\n",
    "- comments_per_likes_ma_2, comments_per_likes_ma_3, comments_per_likes_ma_5 (Moving Averages Going Up/Down): Up: Consistently higher engagement over time may signal sustained interest or ongoing issues attracting attention. Down: Consistently lower engagement may indicate a trend of decreasing visibility or fading interest.\n",
    "- change_followers_ma_3, change_followers_ma_5 (Moving Averages Going Up/Down): Up: An upward trend in follower count could be a sign of growing popularity or successful marketing campaigns. Down: A downward trend might suggest a loss of consumer confidence or interest, potentially affecting the company's future revenue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fafa96f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.754549100Z",
     "start_time": "2024-04-28T09:05:58.694596400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 303 entries, 12 to 30288\n",
      "Data columns (total 28 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Unnamed: 0                        303 non-null    int64  \n",
      " 1   legal_entity                      303 non-null    object \n",
      " 2   date                              303 non-null    object \n",
      " 3   followers                         303 non-null    float64\n",
      " 4   pictures                          303 non-null    float64\n",
      " 5   videos                            303 non-null    float64\n",
      " 6   comments                          303 non-null    float64\n",
      " 7   likes                             303 non-null    float64\n",
      " 8   close                             303 non-null    float64\n",
      " 9   content                           303 non-null    float64\n",
      " 10  likes_per_content                 303 non-null    float64\n",
      " 11  comments_per_likes                303 non-null    float64\n",
      " 12  likes_per_content_weekly_change   303 non-null    float64\n",
      " 13  followers_weekly_change           303 non-null    float64\n",
      " 14  comments_per_likes_weekly_change  303 non-null    float64\n",
      " 15  Close_price_weekly_change         303 non-null    float64\n",
      " 16  comments_per_likes_ma_2           303 non-null    float64\n",
      " 17  change_followers_ma_2             303 non-null    float64\n",
      " 18  Close_price_weekly_change_ma_2    303 non-null    float64\n",
      " 19  comments_per_likes_ma_3           303 non-null    float64\n",
      " 20  change_followers_ma_3             303 non-null    float64\n",
      " 21  Close_price_weekly_change_ma_3    303 non-null    float64\n",
      " 22  comments_per_likes_ma_5           303 non-null    float64\n",
      " 23  change_followers_ma_5             303 non-null    float64\n",
      " 24  Close_price_weekly_change_ma_5    303 non-null    float64\n",
      " 25  anomaly_iso_forest                303 non-null    int32  \n",
      " 26  anomaly_score                     303 non-null    float64\n",
      " 27  outlier_features                  303 non-null    object \n",
      "dtypes: float64(23), int32(1), int64(1), object(3)\n",
      "memory usage: 75.6+ KB\n"
     ]
    }
   ],
   "source": [
    "anomalies_iso_forest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76e219a",
   "metadata": {},
   "source": [
    "### Let´s use these insights in designing our strategy for financial advice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7857b1d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.771730700Z",
     "start_time": "2024-04-28T09:05:58.723129300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\ipykernel_18832\\3420492579.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomalies_iso_forest[\"action\"] = \"Hold\"\n"
     ]
    }
   ],
   "source": [
    "anomalies_iso_forest[\"action\"] = \"Hold\"\n",
    "# We define some \"priorities\" in our strategy:\n",
    "for index, row in anomalies_iso_forest.iterrows():\n",
    "    if \"followers_weekly_change\" in row[\"outlier_features\"]:\n",
    "        if row[\"followers_weekly_change\"] < 0:\n",
    "            anomalies_iso_forest.at[index, \"action\"] = \"Sell\"\n",
    "            continue\n",
    "\n",
    "    if \"comments_per_likes_weekly_change\" in row[\"outlier_features\"]:\n",
    "        if row[\"comments_per_likes_weekly_change\"] > 0:\n",
    "            anomalies_iso_forest.at[index, \"action\"] = \"Sell\"\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e48ea44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.771730700Z",
     "start_time": "2024-04-28T09:05:58.748516900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let´s compare the results against the real values:\n",
    "\n",
    "anomalies_iso_forest[\"action\"].unique()  # We can take the \"Hold\"s out\n",
    "anomalies_iso_forest = anomalies_iso_forest[(anomalies_iso_forest[\"action\"] != \"Hold\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d13fde79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.774530400Z",
     "start_time": "2024-04-28T09:05:58.749039100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JJ\\AppData\\Local\\Temp\\ipykernel_18832\\903216299.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  anomalies_iso_forest.at[index, \"results\"] = 0\n"
     ]
    }
   ],
   "source": [
    "for index, row in anomalies_iso_forest.iterrows():\n",
    "\n",
    "    anomalies_iso_forest.at[index, \"results\"] = 0\n",
    "\n",
    "    if row['action'] == 'Sell' and row['Close_price_weekly_change'] < 0:\n",
    "        anomalies_iso_forest.at[index, \"results\"] = 1\n",
    "\n",
    "    # If the action was 'Buy' and the close price increased\n",
    "    elif row['action'] == 'Buy' and row['Close_price_weekly_change'] > 0:\n",
    "        anomalies_iso_forest.at[index, \"results\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba0535d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.881466700Z",
     "start_time": "2024-04-28T09:05:58.771730700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       results  Close_price_weekly_change  likes_per_content_weekly_change  \\\n3486       1.0                  -4.550362                         7.913884   \n4471       0.0                   9.815949                        59.653652   \n4506       1.0                 -10.129867                        70.618000   \n5086       1.0                  -0.348257                        29.299061   \n5138       1.0                  -0.782856                        80.740575   \n5563       1.0                  -1.771490                        21.034781   \n5620       1.0                  -0.733249                        24.444444   \n5669       1.0                  -0.053061                       193.650794   \n5674       1.0                 -10.011134                        39.925023   \n5680       0.0                  11.171447                         0.273018   \n5701       0.0                   1.254674                       134.407484   \n6238       0.0                  11.158319                        45.499773   \n8023       0.0                   5.011788                        28.502049   \n8058       1.0                  -0.498908                        48.030339   \n8076       1.0                  -0.118916                        29.558844   \n8099       1.0                  -0.984012                        25.346632   \n11044      1.0                  -7.929518                        23.110151   \n11102      1.0                 -10.658312                      1438.935939   \n13473      1.0                  -5.725191                        15.280463   \n13525      1.0                  -4.370884                        51.910405   \n13543      0.0                   1.232867                         6.764117   \n18588      0.0                   3.709954                        21.538281   \n18611      0.0                   5.217393                        24.342968   \n19157      0.0                   8.895328                        46.875000   \n20488      0.0                   7.663555                        72.802839   \n20512      1.0                  -1.629633                        23.128531   \n20538      0.0                   7.764700                        65.747860   \n20653      0.0                  16.764702                        36.338648   \n21512      1.0                  -5.159711                        65.183091   \n21785      1.0                  -1.735417                        49.429429   \n24795      0.0                   0.787399                       -97.665409   \n24985      1.0                  -0.399467                        95.632711   \n26146      0.0                   0.362811                        -7.388034   \n27706      1.0                  -1.477835                       -96.700690   \n27931      0.0                  11.933534                        15.627440   \n28126      1.0                  -0.487820                        82.124126   \n28166      0.0                   4.417673                        13.840698   \n28286      1.0                 -10.294130                        79.343553   \n28363      1.0                  -5.347602                       246.666667   \n30226      1.0                  -8.954122                        31.859995   \n30269      1.0                  -9.879842                         8.741839   \n\n       followers_weekly_change  comments_per_likes_weekly_change  \\\n3486                 14.068905                        386.704955   \n4471                  1.315837                       8718.097702   \n4506                  0.755287                       3840.194944   \n5086                  1.975194                        967.225196   \n5138                  2.879046                       1473.482893   \n5563                 -0.182895                        420.476252   \n5620                  0.654493                       3892.063492   \n5669                  3.110599                       2836.636637   \n5674                  3.062141                       3835.521700   \n5680                  1.062151                        807.819365   \n5701                  0.242272                       1526.734241   \n6238                  1.966835                        574.924395   \n8023                  0.723756                       1545.500047   \n8058                  0.991135                        957.891471   \n8076                  1.047678                       1477.199810   \n8099                  0.745601                       1741.889202   \n11044                 0.866218                       1360.171261   \n11102                85.998608                       5688.209882   \n13473                 4.006630                       2316.889950   \n13525                 5.766544                       7139.813686   \n13543                10.339421                       2461.169418   \n18588                 2.303759                        730.232061   \n18611                 1.765611                       1806.417780   \n19157                 2.090217                       1336.988543   \n20488                 0.942761                        378.708699   \n20512                 0.517350                       1257.453320   \n20538                 1.018840                        659.511676   \n20653                 0.199949                        557.780113   \n21512                 0.649745                       2127.047377   \n21785                 0.379448                       1381.799819   \n24795                 0.299695                        619.189061   \n24985                 0.402040                       8076.300182   \n26146                 3.031180                       3517.103660   \n27706                 0.014171                       3299.844720   \n27931                -6.161181                       1630.217377   \n28126                11.659436                      17274.293821   \n28166                 4.180064                       3832.460299   \n28286                 0.679810                        489.518717   \n28363                 0.289423                        493.466172   \n30226                 0.151213                       1629.482086   \n30269                 0.258846                        694.055285   \n\n       comments_per_likes_ma_2  comments_per_likes_ma_3  \\\n3486                  0.034292                 0.026853   \n4471                  0.673743                 0.454702   \n4506                  0.368968                 0.250997   \n5086                  0.972139                 0.716488   \n5138                  2.200034                 1.571258   \n5563                  0.338153                 0.266909   \n5620                  1.918155                 1.314064   \n5669                  1.346292                 0.926537   \n5674                  1.673588                 1.683071   \n5680                  0.343941                 0.250225   \n5701                  0.612524                 0.431639   \n6238                  0.256861                 0.204042   \n8023                  0.897826                 0.623587   \n8058                  0.691694                 0.491531   \n8076                  0.690872                 0.491993   \n8099                  0.705676                 0.496485   \n11044                 0.353819                 0.249570   \n11102                 0.607361                 0.410860   \n13473                 0.137575                 0.096618   \n13525                 0.217988                 0.147838   \n13543                 0.074358                 0.051840   \n18588                 0.181124                 0.134883   \n18611                 0.343581                 0.240482   \n19157                 0.542958                 0.384848   \n20488                 0.258776                 0.196902   \n20512                 0.754587                 0.535435   \n20538                 0.286854                 0.211979   \n20653                 0.391596                 0.288447   \n21512                 0.313320                 0.217974   \n21785                 0.555768                 0.399062   \n24795                 0.031116                 0.023243   \n24985                 0.708229                 0.478198   \n26146                 0.325138                 0.222367   \n27706                 3.379160                 2.306905   \n27931                 0.168425                 0.119678   \n28126                 0.892617                 0.598479   \n28166                 0.217100                 0.149074   \n28286                 0.760259                 0.558746   \n28363                 1.522690                 1.101665   \n30226                 0.603126                 0.425700   \n30269                 0.508831                 0.373733   \n\n       change_followers_ma_3  comments_per_likes_ma_5  change_followers_ma_5  \n3486               19.531253                 0.020781              11.633047  \n4471                0.729237                 0.280041               0.612228  \n4506                0.403161                 0.156973               0.306951  \n5086                0.900578                 0.582225               0.808305  \n5138                1.122527                 1.064045               0.998782  \n5563               -0.141656                 0.215042              -0.146723  \n5620                0.419770                 0.826091               0.350593  \n5669                1.275760                 0.591305               1.017141  \n5674                1.513768                 1.808480               1.603696  \n5680                1.319896                 0.956857               0.988905  \n5701                0.274678                 0.284809               0.245723  \n6238                0.793663                 0.199699               0.584995  \n8023                0.414556                 0.426089               0.318358  \n8058                0.433023                 0.331544               0.307691  \n8076                0.482428                 0.356044               0.343200  \n8099                0.337888                 0.330955               0.247464  \n11044               0.575544                 0.165368               0.494628  \n11102              29.101981                 0.251257              17.810020  \n13473               1.697572                 0.063893               1.292225  \n13525               2.585974                 0.091782               1.926351  \n13543               4.295390                 0.035350               2.997780  \n18588               0.805259                 0.101351               0.479182  \n18611               0.627862                 0.160681               0.379608  \n19157               2.552532                 0.245720               1.793579  \n20488               0.965654                 0.153684               0.975550  \n20512               0.466966                 0.352010               0.417243  \n20538               1.269966                 0.228240               0.970133  \n20653               0.078957                 0.357848               0.061673  \n21512               0.395337                 0.312888               0.328161  \n21785               0.276540                 0.273093               0.283912  \n24795               4.022330                 0.016926               3.932462  \n24985               0.183678                 0.293885               0.136621  \n26146               1.561485                 0.139323               1.386520  \n27706               0.038726                 1.442832               0.028762  \n27931              -1.951414                 0.094390              -1.106817  \n28126               4.486502                 0.363516               3.192518  \n28166               1.652094                 0.095583               1.152163  \n28286               0.169293                 0.406854               0.159626  \n28363               0.188777                 0.749881               0.119424  \n30226               0.546746                 0.290015               0.299416  \n30269               0.089333                 0.388587               0.053469  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>results</th>\n      <th>Close_price_weekly_change</th>\n      <th>likes_per_content_weekly_change</th>\n      <th>followers_weekly_change</th>\n      <th>comments_per_likes_weekly_change</th>\n      <th>comments_per_likes_ma_2</th>\n      <th>comments_per_likes_ma_3</th>\n      <th>change_followers_ma_3</th>\n      <th>comments_per_likes_ma_5</th>\n      <th>change_followers_ma_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3486</th>\n      <td>1.0</td>\n      <td>-4.550362</td>\n      <td>7.913884</td>\n      <td>14.068905</td>\n      <td>386.704955</td>\n      <td>0.034292</td>\n      <td>0.026853</td>\n      <td>19.531253</td>\n      <td>0.020781</td>\n      <td>11.633047</td>\n    </tr>\n    <tr>\n      <th>4471</th>\n      <td>0.0</td>\n      <td>9.815949</td>\n      <td>59.653652</td>\n      <td>1.315837</td>\n      <td>8718.097702</td>\n      <td>0.673743</td>\n      <td>0.454702</td>\n      <td>0.729237</td>\n      <td>0.280041</td>\n      <td>0.612228</td>\n    </tr>\n    <tr>\n      <th>4506</th>\n      <td>1.0</td>\n      <td>-10.129867</td>\n      <td>70.618000</td>\n      <td>0.755287</td>\n      <td>3840.194944</td>\n      <td>0.368968</td>\n      <td>0.250997</td>\n      <td>0.403161</td>\n      <td>0.156973</td>\n      <td>0.306951</td>\n    </tr>\n    <tr>\n      <th>5086</th>\n      <td>1.0</td>\n      <td>-0.348257</td>\n      <td>29.299061</td>\n      <td>1.975194</td>\n      <td>967.225196</td>\n      <td>0.972139</td>\n      <td>0.716488</td>\n      <td>0.900578</td>\n      <td>0.582225</td>\n      <td>0.808305</td>\n    </tr>\n    <tr>\n      <th>5138</th>\n      <td>1.0</td>\n      <td>-0.782856</td>\n      <td>80.740575</td>\n      <td>2.879046</td>\n      <td>1473.482893</td>\n      <td>2.200034</td>\n      <td>1.571258</td>\n      <td>1.122527</td>\n      <td>1.064045</td>\n      <td>0.998782</td>\n    </tr>\n    <tr>\n      <th>5563</th>\n      <td>1.0</td>\n      <td>-1.771490</td>\n      <td>21.034781</td>\n      <td>-0.182895</td>\n      <td>420.476252</td>\n      <td>0.338153</td>\n      <td>0.266909</td>\n      <td>-0.141656</td>\n      <td>0.215042</td>\n      <td>-0.146723</td>\n    </tr>\n    <tr>\n      <th>5620</th>\n      <td>1.0</td>\n      <td>-0.733249</td>\n      <td>24.444444</td>\n      <td>0.654493</td>\n      <td>3892.063492</td>\n      <td>1.918155</td>\n      <td>1.314064</td>\n      <td>0.419770</td>\n      <td>0.826091</td>\n      <td>0.350593</td>\n    </tr>\n    <tr>\n      <th>5669</th>\n      <td>1.0</td>\n      <td>-0.053061</td>\n      <td>193.650794</td>\n      <td>3.110599</td>\n      <td>2836.636637</td>\n      <td>1.346292</td>\n      <td>0.926537</td>\n      <td>1.275760</td>\n      <td>0.591305</td>\n      <td>1.017141</td>\n    </tr>\n    <tr>\n      <th>5674</th>\n      <td>1.0</td>\n      <td>-10.011134</td>\n      <td>39.925023</td>\n      <td>3.062141</td>\n      <td>3835.521700</td>\n      <td>1.673588</td>\n      <td>1.683071</td>\n      <td>1.513768</td>\n      <td>1.808480</td>\n      <td>1.603696</td>\n    </tr>\n    <tr>\n      <th>5680</th>\n      <td>0.0</td>\n      <td>11.171447</td>\n      <td>0.273018</td>\n      <td>1.062151</td>\n      <td>807.819365</td>\n      <td>0.343941</td>\n      <td>0.250225</td>\n      <td>1.319896</td>\n      <td>0.956857</td>\n      <td>0.988905</td>\n    </tr>\n    <tr>\n      <th>5701</th>\n      <td>0.0</td>\n      <td>1.254674</td>\n      <td>134.407484</td>\n      <td>0.242272</td>\n      <td>1526.734241</td>\n      <td>0.612524</td>\n      <td>0.431639</td>\n      <td>0.274678</td>\n      <td>0.284809</td>\n      <td>0.245723</td>\n    </tr>\n    <tr>\n      <th>6238</th>\n      <td>0.0</td>\n      <td>11.158319</td>\n      <td>45.499773</td>\n      <td>1.966835</td>\n      <td>574.924395</td>\n      <td>0.256861</td>\n      <td>0.204042</td>\n      <td>0.793663</td>\n      <td>0.199699</td>\n      <td>0.584995</td>\n    </tr>\n    <tr>\n      <th>8023</th>\n      <td>0.0</td>\n      <td>5.011788</td>\n      <td>28.502049</td>\n      <td>0.723756</td>\n      <td>1545.500047</td>\n      <td>0.897826</td>\n      <td>0.623587</td>\n      <td>0.414556</td>\n      <td>0.426089</td>\n      <td>0.318358</td>\n    </tr>\n    <tr>\n      <th>8058</th>\n      <td>1.0</td>\n      <td>-0.498908</td>\n      <td>48.030339</td>\n      <td>0.991135</td>\n      <td>957.891471</td>\n      <td>0.691694</td>\n      <td>0.491531</td>\n      <td>0.433023</td>\n      <td>0.331544</td>\n      <td>0.307691</td>\n    </tr>\n    <tr>\n      <th>8076</th>\n      <td>1.0</td>\n      <td>-0.118916</td>\n      <td>29.558844</td>\n      <td>1.047678</td>\n      <td>1477.199810</td>\n      <td>0.690872</td>\n      <td>0.491993</td>\n      <td>0.482428</td>\n      <td>0.356044</td>\n      <td>0.343200</td>\n    </tr>\n    <tr>\n      <th>8099</th>\n      <td>1.0</td>\n      <td>-0.984012</td>\n      <td>25.346632</td>\n      <td>0.745601</td>\n      <td>1741.889202</td>\n      <td>0.705676</td>\n      <td>0.496485</td>\n      <td>0.337888</td>\n      <td>0.330955</td>\n      <td>0.247464</td>\n    </tr>\n    <tr>\n      <th>11044</th>\n      <td>1.0</td>\n      <td>-7.929518</td>\n      <td>23.110151</td>\n      <td>0.866218</td>\n      <td>1360.171261</td>\n      <td>0.353819</td>\n      <td>0.249570</td>\n      <td>0.575544</td>\n      <td>0.165368</td>\n      <td>0.494628</td>\n    </tr>\n    <tr>\n      <th>11102</th>\n      <td>1.0</td>\n      <td>-10.658312</td>\n      <td>1438.935939</td>\n      <td>85.998608</td>\n      <td>5688.209882</td>\n      <td>0.607361</td>\n      <td>0.410860</td>\n      <td>29.101981</td>\n      <td>0.251257</td>\n      <td>17.810020</td>\n    </tr>\n    <tr>\n      <th>13473</th>\n      <td>1.0</td>\n      <td>-5.725191</td>\n      <td>15.280463</td>\n      <td>4.006630</td>\n      <td>2316.889950</td>\n      <td>0.137575</td>\n      <td>0.096618</td>\n      <td>1.697572</td>\n      <td>0.063893</td>\n      <td>1.292225</td>\n    </tr>\n    <tr>\n      <th>13525</th>\n      <td>1.0</td>\n      <td>-4.370884</td>\n      <td>51.910405</td>\n      <td>5.766544</td>\n      <td>7139.813686</td>\n      <td>0.217988</td>\n      <td>0.147838</td>\n      <td>2.585974</td>\n      <td>0.091782</td>\n      <td>1.926351</td>\n    </tr>\n    <tr>\n      <th>13543</th>\n      <td>0.0</td>\n      <td>1.232867</td>\n      <td>6.764117</td>\n      <td>10.339421</td>\n      <td>2461.169418</td>\n      <td>0.074358</td>\n      <td>0.051840</td>\n      <td>4.295390</td>\n      <td>0.035350</td>\n      <td>2.997780</td>\n    </tr>\n    <tr>\n      <th>18588</th>\n      <td>0.0</td>\n      <td>3.709954</td>\n      <td>21.538281</td>\n      <td>2.303759</td>\n      <td>730.232061</td>\n      <td>0.181124</td>\n      <td>0.134883</td>\n      <td>0.805259</td>\n      <td>0.101351</td>\n      <td>0.479182</td>\n    </tr>\n    <tr>\n      <th>18611</th>\n      <td>0.0</td>\n      <td>5.217393</td>\n      <td>24.342968</td>\n      <td>1.765611</td>\n      <td>1806.417780</td>\n      <td>0.343581</td>\n      <td>0.240482</td>\n      <td>0.627862</td>\n      <td>0.160681</td>\n      <td>0.379608</td>\n    </tr>\n    <tr>\n      <th>19157</th>\n      <td>0.0</td>\n      <td>8.895328</td>\n      <td>46.875000</td>\n      <td>2.090217</td>\n      <td>1336.988543</td>\n      <td>0.542958</td>\n      <td>0.384848</td>\n      <td>2.552532</td>\n      <td>0.245720</td>\n      <td>1.793579</td>\n    </tr>\n    <tr>\n      <th>20488</th>\n      <td>0.0</td>\n      <td>7.663555</td>\n      <td>72.802839</td>\n      <td>0.942761</td>\n      <td>378.708699</td>\n      <td>0.258776</td>\n      <td>0.196902</td>\n      <td>0.965654</td>\n      <td>0.153684</td>\n      <td>0.975550</td>\n    </tr>\n    <tr>\n      <th>20512</th>\n      <td>1.0</td>\n      <td>-1.629633</td>\n      <td>23.128531</td>\n      <td>0.517350</td>\n      <td>1257.453320</td>\n      <td>0.754587</td>\n      <td>0.535435</td>\n      <td>0.466966</td>\n      <td>0.352010</td>\n      <td>0.417243</td>\n    </tr>\n    <tr>\n      <th>20538</th>\n      <td>0.0</td>\n      <td>7.764700</td>\n      <td>65.747860</td>\n      <td>1.018840</td>\n      <td>659.511676</td>\n      <td>0.286854</td>\n      <td>0.211979</td>\n      <td>1.269966</td>\n      <td>0.228240</td>\n      <td>0.970133</td>\n    </tr>\n    <tr>\n      <th>20653</th>\n      <td>0.0</td>\n      <td>16.764702</td>\n      <td>36.338648</td>\n      <td>0.199949</td>\n      <td>557.780113</td>\n      <td>0.391596</td>\n      <td>0.288447</td>\n      <td>0.078957</td>\n      <td>0.357848</td>\n      <td>0.061673</td>\n    </tr>\n    <tr>\n      <th>21512</th>\n      <td>1.0</td>\n      <td>-5.159711</td>\n      <td>65.183091</td>\n      <td>0.649745</td>\n      <td>2127.047377</td>\n      <td>0.313320</td>\n      <td>0.217974</td>\n      <td>0.395337</td>\n      <td>0.312888</td>\n      <td>0.328161</td>\n    </tr>\n    <tr>\n      <th>21785</th>\n      <td>1.0</td>\n      <td>-1.735417</td>\n      <td>49.429429</td>\n      <td>0.379448</td>\n      <td>1381.799819</td>\n      <td>0.555768</td>\n      <td>0.399062</td>\n      <td>0.276540</td>\n      <td>0.273093</td>\n      <td>0.283912</td>\n    </tr>\n    <tr>\n      <th>24795</th>\n      <td>0.0</td>\n      <td>0.787399</td>\n      <td>-97.665409</td>\n      <td>0.299695</td>\n      <td>619.189061</td>\n      <td>0.031116</td>\n      <td>0.023243</td>\n      <td>4.022330</td>\n      <td>0.016926</td>\n      <td>3.932462</td>\n    </tr>\n    <tr>\n      <th>24985</th>\n      <td>1.0</td>\n      <td>-0.399467</td>\n      <td>95.632711</td>\n      <td>0.402040</td>\n      <td>8076.300182</td>\n      <td>0.708229</td>\n      <td>0.478198</td>\n      <td>0.183678</td>\n      <td>0.293885</td>\n      <td>0.136621</td>\n    </tr>\n    <tr>\n      <th>26146</th>\n      <td>0.0</td>\n      <td>0.362811</td>\n      <td>-7.388034</td>\n      <td>3.031180</td>\n      <td>3517.103660</td>\n      <td>0.325138</td>\n      <td>0.222367</td>\n      <td>1.561485</td>\n      <td>0.139323</td>\n      <td>1.386520</td>\n    </tr>\n    <tr>\n      <th>27706</th>\n      <td>1.0</td>\n      <td>-1.477835</td>\n      <td>-96.700690</td>\n      <td>0.014171</td>\n      <td>3299.844720</td>\n      <td>3.379160</td>\n      <td>2.306905</td>\n      <td>0.038726</td>\n      <td>1.442832</td>\n      <td>0.028762</td>\n    </tr>\n    <tr>\n      <th>27931</th>\n      <td>0.0</td>\n      <td>11.933534</td>\n      <td>15.627440</td>\n      <td>-6.161181</td>\n      <td>1630.217377</td>\n      <td>0.168425</td>\n      <td>0.119678</td>\n      <td>-1.951414</td>\n      <td>0.094390</td>\n      <td>-1.106817</td>\n    </tr>\n    <tr>\n      <th>28126</th>\n      <td>1.0</td>\n      <td>-0.487820</td>\n      <td>82.124126</td>\n      <td>11.659436</td>\n      <td>17274.293821</td>\n      <td>0.892617</td>\n      <td>0.598479</td>\n      <td>4.486502</td>\n      <td>0.363516</td>\n      <td>3.192518</td>\n    </tr>\n    <tr>\n      <th>28166</th>\n      <td>0.0</td>\n      <td>4.417673</td>\n      <td>13.840698</td>\n      <td>4.180064</td>\n      <td>3832.460299</td>\n      <td>0.217100</td>\n      <td>0.149074</td>\n      <td>1.652094</td>\n      <td>0.095583</td>\n      <td>1.152163</td>\n    </tr>\n    <tr>\n      <th>28286</th>\n      <td>1.0</td>\n      <td>-10.294130</td>\n      <td>79.343553</td>\n      <td>0.679810</td>\n      <td>489.518717</td>\n      <td>0.760259</td>\n      <td>0.558746</td>\n      <td>0.169293</td>\n      <td>0.406854</td>\n      <td>0.159626</td>\n    </tr>\n    <tr>\n      <th>28363</th>\n      <td>1.0</td>\n      <td>-5.347602</td>\n      <td>246.666667</td>\n      <td>0.289423</td>\n      <td>493.466172</td>\n      <td>1.522690</td>\n      <td>1.101665</td>\n      <td>0.188777</td>\n      <td>0.749881</td>\n      <td>0.119424</td>\n    </tr>\n    <tr>\n      <th>30226</th>\n      <td>1.0</td>\n      <td>-8.954122</td>\n      <td>31.859995</td>\n      <td>0.151213</td>\n      <td>1629.482086</td>\n      <td>0.603126</td>\n      <td>0.425700</td>\n      <td>0.546746</td>\n      <td>0.290015</td>\n      <td>0.299416</td>\n    </tr>\n    <tr>\n      <th>30269</th>\n      <td>1.0</td>\n      <td>-9.879842</td>\n      <td>8.741839</td>\n      <td>0.258846</td>\n      <td>694.055285</td>\n      <td>0.508831</td>\n      <td>0.373733</td>\n      <td>0.089333</td>\n      <td>0.388587</td>\n      <td>0.053469</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomalies_iso_forest[[\"results\", \"Close_price_weekly_change\",\n",
    "                      \"likes_per_content_weekly_change\", \n",
    "    \"followers_weekly_change\", \n",
    "    \"comments_per_likes_weekly_change\",\n",
    "    \"comments_per_likes_ma_2\",\n",
    "    \"comments_per_likes_ma_3\",\n",
    "    \"change_followers_ma_3\",\n",
    "    \"comments_per_likes_ma_5\",\n",
    "    \"change_followers_ma_5\" ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "877432b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-28T09:05:58.898002100Z",
     "start_time": "2024-04-28T09:05:58.801915600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.6097560975609756"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(anomalies_iso_forest[\"results\"])/len(anomalies_iso_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We find an accuracy of nearly 61% in the strategy. Limitations of the strategy include the timespan convered by the dataset, not taking into account comisions, and not evaluating the total profit."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a19ffa1b9faee49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "In order to throughoutly inspect the performance of our model, we now calculate the confusion matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dc8cfeacbe0d48a"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6097560975609756\n",
      "Precision: 0.6097560975609756\n",
      "Recall: 1.0\n",
      "F1-Score: 0.7575757575757575\n"
     ]
    }
   ],
   "source": [
    "# Initialize counters\n",
    "TP = TN = FP = FN = 0\n",
    "\n",
    "for index, row in anomalies_iso_forest.iterrows():\n",
    "    predicted = 0\n",
    "    actual = 0\n",
    "\n",
    "    if row['action'] == 'Sell' and row['Close_price_weekly_change'] < 0:\n",
    "        predicted = 1\n",
    "        actual = 1\n",
    "    elif row['action'] == 'Sell' and row['Close_price_weekly_change'] >= 0:\n",
    "        predicted = 1\n",
    "    elif row['action'] == 'Buy' and row['Close_price_weekly_change'] > 0:\n",
    "        predicted = 1\n",
    "        actual = 1\n",
    "    elif row['action'] == 'Buy' and row['Close_price_weekly_change'] <= 0:\n",
    "        predicted = 1\n",
    "\n",
    "    # Update confusion matrix counts\n",
    "    if predicted == 1 and actual == 1:\n",
    "        TP += 1\n",
    "    elif predicted == 0 and actual == 0:\n",
    "        TN += 1\n",
    "    elif predicted == 1 and actual == 0:\n",
    "        FP += 1\n",
    "    elif predicted == 0 and actual == 1:\n",
    "        FN += 1\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "# Output results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T09:10:37.660846600Z",
     "start_time": "2024-04-28T09:10:37.627102900Z"
    }
   },
   "id": "75675a8dd8b17d3a"
  },
  {
   "cell_type": "markdown",
   "id": "84f7c88e",
   "metadata": {},
   "source": [
    "## Model Performance Metrics\n",
    "\n",
    "The following are the calculated performance metrics for the stock prediction model:\n",
    "\n",
    "- **Accuracy**: `60.98%`\n",
    "  - Indicates that about 61% of all predictions (both 'Buy'/'Sell' and not 'Buy'/'Sell') by the model are correct.\n",
    "\n",
    "- **Precision**: `60.98%`\n",
    "  - This tells us that when the model predicts a 'Buy' or 'Sell' action, there's a 61% chance that it is correct.\n",
    "\n",
    "- **Recall**: `100%`\n",
    "  - The model correctly identifies all actual 'Buy' or 'Sell' cases, suggesting no missed positive predictions.\n",
    "\n",
    "- **F1-Score**: `75.76%`\n",
    "  - A measure of the model's balance between precision and recall. A higher F1-score indicates a better balance, with an approximate value of 76% in this case.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- The **high recall** (100%) suggests that the model is very good at identifying all true positive cases. However, the fact that precision is not as high indicates the model might be predicting too many positives (over-predicting 'Buy' or 'Sell').\n",
    "\n",
    "- The **accuracy** and **precision** both standing at about 61% are very good results, given the usually low accuracy when predicting stock market prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1cd656",
   "metadata": {},
   "source": [
    "The goal of the strategy is to be able to advice that with a high probability the stock price will decrease on the next day. One advantage of the model is that, as it relies on unsupervised learning and knowledge of the industry, the strategy is less likely to be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69daa93b252aa113"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
